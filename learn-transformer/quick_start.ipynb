{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c3f8b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2025/7/11\n",
    "# zhangzhong\n",
    "# https://huggingface.co/docs/transformers/quicktour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33fbf399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# device_map=\"auto\" automatically allocates the model weights to your fastest device first, which is typically the GPU.\n",
    "# torch_dtype=\"auto\" directly initializes the model weights in the data type theyâ€™re stored in, which can help avoid loading the weights twice (PyTorch loads weights in torch.float32 by default).\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\", torch_dtype=\"auto\", device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67fe7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  464,  3200,   284, 16871,   257,   922, 12187,   318,   220]],\n",
       "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize the text and return PyTorch tensors with the tokenizer.\n",
    "model_inputs = tokenizer([\"The secret to baking a good cake is \"], return_tensors=\"pt\").to(\"cuda\")\n",
    "# The tokenizer returns a dictionary with three important items:\n",
    "# input_ids are the indices corresponding to each token in the sentence.\n",
    "# attention_mask indicates whether a token should be attended to or not.\n",
    "# token_type_ids identifies which sequence a token belongs to when there is more than one sequence.\n",
    "model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b787ed0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"The secret to baking a good cake is \\xa0to make sure that the cake is moist and not too moist. \\xa0If you're baking a cake with a lot of cake, you'll want to make sure that the cake is moist and not\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The model is now ready for inference or training.\n",
    "# For inference pass the tokenized inputs to the generate() to generate text.\n",
    "generated_ids = model.generate(**model_inputs, max_length=50)\n",
    "# Decode the token ids back into text with batch_decode().\n",
    "tokenizer.batch_decode(generated_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c3f9fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The secret to baking a good cake is \\xa0truly delicious. For the ultimate in flavor you can add a pinch of salt or lemon juice. With all of the information in the recipe, we can find out why making a good cake is so important.\\n1. Use a rolling pin to roll the cake into the shape you like.\\n2. Assemble the cake.\\n3. Take a sheet pan and mix together the butter, sugar, baking soda, and salt in with the sugar mixture.\\n4. Add the sugar and mix until thoroughly combined.\\n5. Pour the batter over the pan and let it cool for a few minutes.\\n6. Bake the cake for about 20 minutes.\\n7. Let the cake cool completely before removing.\\n8. Using a spatula or a fork, remove the cake from the center of the cookie sheet and place it on a baking sheet lined with parchment paper.\\n9. Bake for another 20 minutes or so.\\n10. Once the cake cools completely, roll it up into a ball and place it on the rack.\\n11. Remove from the oven and let cool for up to 10 minutes, or until firm.\\n12. The cake will come out to be a very nice, creamy cake.\\n13. You can also'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline, pre defined inference tasks\n",
    "# such as: text generation, image segmentation, automatic speech recognition\n",
    "from transformers import pipeline\n",
    "\n",
    "tg_pipeline = pipeline(\"text-generation\", model=\"gpt2\", device=\"cuda\")\n",
    "tg_pipeline(\"The secret to baking a good cake is \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe5e063b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50-panoptic were not used when initializing DetrForSegmentation: ['detr.model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'detr.model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'detr.model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'detr.model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bird', 'bird')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image segmentation pipeline\n",
    "seg_pipeline = pipeline(\"image-segmentation\", model=\"facebook/detr-resnet-50-panoptic\", device=\"cuda\")\n",
    "segments = seg_pipeline(\"https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png\")\n",
    "segments[0][\"label\"], segments[1][\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d481a348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "/data2/zhangzhong/src/deep_learning/.venv/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:604: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
      "Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': ' He hoped there would be stew for dinner, turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out in thick, peppered, flour-fattened sauce.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# automatic speech recognition\n",
    "# ubuntu: sudo apt install ffmpeg\n",
    "asr = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-large-v3\", device=\"cuda\")\n",
    "asr(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f3cc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe6cc7f293748f4a051bc29c248f8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2f8d1cc09f4340b1d4e1cdc4c9a0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0baa1b315b77467c87832fbd474c7270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d28558d91f2b430cb5127ccc3829baf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7152d99d9bc5412581fd73d99ad14270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610ff6fd0fa64ebea0d9c312c626eaad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a8223f4e5b41958579b5aa2eb6eea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.parquet:   0%|          | 0.00/699k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f99bf0c9794d7f8f26bd60e5269a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation.parquet:   0%|          | 0.00/90.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c6cd6c1d9347fd9b015e19824410dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.parquet:   0%|          | 0.00/92.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61ae7336fd44727a6760933f31a8f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f402e0958e847198c1922a22b3f3bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcbf61b2b104d69a3a89d3aa7de54d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Trainer is a complete training and evaluation loop for PyTorch models.\n",
    "# You only need a model, dataset, a preprocessor, and a data collator to build batches of data from the dataset.\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer \n",
    "from datasets import load_dataset\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "dataset = load_dataset(\"rotten_tomatoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e24d4c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4b1bb472aa4433b32d95c050407a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268096e138a74f39a22b08911e2771ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d659ae2ee84e4c897c3a942f1a9020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a function to tokenize the text and convert it to pytorch tensors\n",
    "# apply this function to the whole dataset through the dataset.map() method\n",
    "def tokenize_dataset(dataset):\n",
    "    return tokenizer(dataset[\"text\"])\n",
    "\n",
    "dataset = dataset.map(tokenize_dataset, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfddd8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a data collator to create batches of data and pass the tokenizer to it\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Use the TrainingArguments class to customize the training process., or just use the default settings.\n",
    "from transformers import TrainingArguments \n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./huggingface/distilbert-rotten-tomatoes\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f2647ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_806746/186838011.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/data2/zhangzhong/src/deep_learning/.venv/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='534' max='534' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [534/534 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.352100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/zhangzhong/src/deep_learning/.venv/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=534, training_loss=0.3461690091908201, metrics={'train_runtime': 68.3446, 'train_samples_per_second': 249.617, 'train_steps_per_second': 7.813, 'total_flos': 232302799025112.0, 'train_loss': 0.3461690091908201, 'epoch': 2.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "# Finally, pass all these separate components to Trainer and call train() to start.\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
