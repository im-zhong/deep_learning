{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023/11/26\n",
    "# zhangzhong\n",
    "\n",
    "from module.vision.resnet import ResNet18, SmallResNet18\n",
    "# import torchsummary  # type: ignore\n",
    "from mytorch.data.cifar10 import CIFAR10Dataset, cifar10_predict\n",
    "from mytorch.data.svhn import SVHNDataset\n",
    "import torch\n",
    "from mytorch import training, utils\n",
    "import json\n",
    "from torch import nn, Tensor\n",
    "from mytorch import utils\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import LinearLR, CosineAnnealingLR, SequentialLR\n",
    "from mytorch.data.mnist import MNISTDataset, FashionMNISTDataset\n",
    "\n",
    "def test_small_resnet_on_svhn() -> None:\n",
    "    batch_size = 128\n",
    "    num_workers = 16\n",
    "    svhn = SVHNDataset(num_workers=num_workers)\n",
    "    # cifar10 = FashionMNISTDataset()\n",
    "    train_dataloader = svhn.get_train_dataloader(batch_size=batch_size)\n",
    "    val_dataloader = svhn.get_val_dataloader(batch_size=batch_size)\n",
    "    test_dataloader = svhn.get_test_dataloader(batch_size=batch_size)\n",
    "\n",
    "    tag = 'resnet18_svhn_6'\n",
    "    net = SmallResNet18()\n",
    "\n",
    "    lr: float = 0.1\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    warmup_epochs = 5\n",
    "    num_epochs = 0\n",
    "    scheduler = SequentialLR(\n",
    "        optimizer=optimizer,\n",
    "        schedulers=[\n",
    "            LinearLR(optimizer=optimizer, start_factor=0.1, total_iters=warmup_epochs),\n",
    "            CosineAnnealingLR(optimizer=optimizer, T_max=num_epochs-warmup_epochs)\n",
    "        ],\n",
    "        milestones=[warmup_epochs]\n",
    "    )\n",
    "    device = utils.get_device()\n",
    "    trainer = training.TrainerV2(\n",
    "        model=net,\n",
    "        loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=num_epochs,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        test_dataloader=test_dataloader,\n",
    "        scheduler=scheduler,\n",
    "        device=device)\n",
    "\n",
    "    trainer.train(tag=tag)\n",
    "    pretrained_model = trainer.model\n",
    "\n",
    "    layers = ['net.last.AdaptiveMaxPool2d', \n",
    "              'net.last.LazyLinear1', \n",
    "              'net.last.BatchNorm', \n",
    "              'net.last.ReLU',\n",
    "              # 'net.last.Dropout'\n",
    "              ]\n",
    "    hook = utils.RegisterIntermediateOutputHook(model=pretrained_model, layers=layers)\n",
    "\n",
    "    # forward\n",
    "    intermediate_outputs: dict[str, list[Tensor]] = {}\n",
    "    for x, y in tqdm(svhn.get_test_dataloader(batch_size=batch_size)):\n",
    "        x = x.to(device)\n",
    "        y = pretrained_model(x)\n",
    "        \n",
    "        output = hook.get_intermediate_output()\n",
    "        for layer in layers:\n",
    "            if layer not in intermediate_outputs:\n",
    "                intermediate_outputs[layer] = []\n",
    "            intermediate_outputs[layer].append(output[layer])\n",
    "   \n",
    "    for layer in layers:\n",
    "        outputs = intermediate_outputs[layer]\n",
    "        outputs = torch.cat(outputs, dim=0)\n",
    "        utils.draw_tsne(data=outputs, labels=svhn.test_dataset.labels)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: datasets/svhn/train_32x32.mat\n",
      "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to datasets/svhn/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64275384/64275384 [00:12<00:00, 4954499.06it/s] \n",
      "/home/zhangzhong/anaconda3/envs/dl/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/zhangzhong/anaconda3/envs/dl/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'Dropout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_small_resnet_on_svhn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 61\u001b[0m, in \u001b[0;36mtest_small_resnet_on_svhn\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m pretrained_model \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m     56\u001b[0m layers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet.last.AdaptiveMaxPool2d\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     57\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet.last.LazyLinear1\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     58\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet.last.BatchNorm\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     59\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet.last.ReLU\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     60\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet.last.Dropout\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 61\u001b[0m hook \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRegisterIntermediateOutputHook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# forward\u001b[39;00m\n\u001b[1;32m     64\u001b[0m intermediate_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[Tensor]] \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/src/deep_learning/mytorch/utils.py:127\u001b[0m, in \u001b[0;36mRegisterIntermediateOutputHook.__init__\u001b[0;34m(self, model, layers)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks[layer] \u001b[38;5;241m=\u001b[39m IntermediateOutputHook()\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mappend(\u001b[43mget_nested_attr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mregister_forward_hook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks[layer]))\n",
      "File \u001b[0;32m~/src/deep_learning/mytorch/utils.py:115\u001b[0m, in \u001b[0;36mget_nested_attr\u001b[0;34m(obj, attr_path)\u001b[0m\n\u001b[1;32m    113\u001b[0m attrs \u001b[38;5;241m=\u001b[39m attr_path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m attrs:\n\u001b[0;32m--> 115\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'Dropout'"
     ]
    }
   ],
   "source": [
    "test_small_resnet_on_svhn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
